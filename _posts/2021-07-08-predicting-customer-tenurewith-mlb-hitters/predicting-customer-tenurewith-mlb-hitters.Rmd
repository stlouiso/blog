---
title: "Predicting Customer Tenure...with MLB Hitters"
description: |
  How will long will a customer stay with our business or, in this case, how long will a MLB hitter stay in the MLB? In this post, I go through the value of knowing how long a customer will be with an organization, EDA of MLB data, how to clean and setup data for modeling, fitting a linear model and a gradient boosted tree model with xgBoost.
author:
  - name: Louis Oberdiear
    url: thelob.blog/louisoberdiear
date: 06-24-2021
output:
  distill::distill_article:
    toc: true
    highlight: default
    code_folding: true
preview: corrplot.png
categories:
  - customer tenure
  - customer lifetime value
  - customer series
  - data science
  - rstats
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
options(scipen = 999)
```


# Intro: The Why
I believe being able to know how long a customer will be with your business is inherently valuable, but why exactly?

#### First scenario: Customer A
Let's pose a few scenarios. The first scenario is that we know Customer A will only be a customer with us for two years. In this scenario, customers stay with our business on average for ten years so two years is relatively short. Is it valuable to know that Customer A won't be with us very long? What can we do about it?

Well, in my mind, we have two different paths. The *Abandonment* path and the *Retainment* path. Knowing Customer A will only be with us for two years, we can simply cut our losses and not put anymore money into Customer A whether that be through advertisement or discounts and this would be the *Abandonment* path. 

On the other hand, we could try and figure out different ways to extend their stay with us through different interventions and this would be the *Retainment* path. We could try a number of different interventions and measure their effectiveness and their return on investment. 

#### Second Scenario: Customer B

What about the other end of the spectrum where we know a customer will be with us for 15 years. This is Customer B. Is it valuable to know we have a potentially very loyal customer?

Again, I see two paths of treatment. The first path is the *Stay the Course* path where we treat them exactly how we would normally treat them. We know they will be with us a long time so why change anything?

The second path is the *Up Sell Path* where we give them more attention and try to get our hooks in deeper by offering more and more products to them. Maybe even give them special discounts and reward them for being a loyal customer and hopefully turning Customer B into a brand ambassador that will recommend our organization to their friends and family.  

I think looking at this two extreme scenarios show how knowing customer tenure is valuable, but I have another reason in mind. We are going to predict customer tenure in order to calculate *Customer Lifetime Value*. 

## Customer Lifetime Value

There are many ways to calculate Customer Lifetime Value and different formulas will calculate at different organization levels. For example, some formulas calculate overall Customer Lifetime Value. This will let you know the value of an average customer. Knowing the value of an average customer makes sense if an organization is trying to calculate the return on investment on different customer acquisition and retainment efforts. 

That's not my goal here, however. I want to know how valuable a customer is to the company on an individual basis. Some customers are more valuable than others and I want to be able to identify them. The main goal here is to be able to identify early on the potential lifetime value of a customer and then use the treatments mentioned above. 

I have seen some customer level CLV calculations simply use average yearly monetary value and multiply it by the average customer tenure. This works well as a rough estimate but I want to be more precise and having a more precise tenure estimate will lead to more precise CLV estimates. 

In this example, our customers are going to be MLB hitters. We are going to be predicting how many years a hitter stays in the MLB. Then in the next blog post, we will use the predicted tenure to estimate the lifetime value for hitters. 

# The Data

Here are the packages used for this post:

```{r load-packages, message=FALSE, echo=FALSE}
library(lubridate)
library(tidylog)
library(broom)
library(DataExplorer)
library(tidymodels)
library(tidyverse)
library(skimr)
library(gt)
library(performance)
library(GGally)
```

We'll again be using the R package `Lahman`. In the `Lahman` package, there is multiple datasets. Here is a description of the dataset contained in the `Lahman` package:

```{r view-lahman-data}
library(Lahman)
Lahman::LahmanData %>% 
  as_tibble() %>%
  gt()
```
The People dataset looks like a good place to start. 

```{r}
data(People)
glimpse(People) 
```

We can use their debut, finalGame, and birthDate. This will give us the ability to calculate year number in league (e.g. 1st year in league, 2nd, etc.), their age, and their final tenure. 

We are going to be predicting hitters so we will definitely use the Batting dataset. 

```{r}
data(Batting)
glimpse(Batting)
```

Now let's combine the People and the Batting datasets. 

```{r combine-data, message=FALSE, echo=FALSE}
pitchers <- Lahman::Pitching %>%
  select(playerID) %>%
  distinct()

old_players <- People %>%
  filter(ymd(debut) < '1961-01-01')

people_tenure <- People %>%
  select(playerID, nameFirst, nameLast, birthDate, debut, finalGame) %>%
  filter(!is.na(finalGame)) %>%
  filter(ymd(finalGame) < '2018-01-01') %>%
  anti_join(old_players) %>%
  inner_join(Batting) %>%
  group_by(playerID, yearID) %>%
  summarise(nameFirst = first(nameFirst),
            nameLast = first(nameLast),
            birthDate = first(birthDate),
            debut = first(debut),
            finalGame = first(finalGame),
            stint = first(stint),
            teamID = first(teamID),
            lgID = first(lgID),
            G = sum(G),
            AB = sum(AB),
            R = sum(R),
            H = sum(H),
            X2B = sum(X2B),
            X3B = sum(X3B),
            HR = sum(HR),
            RBI = sum(RBI),
            SB = sum(SB),
            CS = sum(CS),
            BB = sum(BB),
            SO = sum(SO),
            IBB = sum(IBB),
            HBP = sum(HBP),
            SH = sum(SH),
            SF = sum(SF),
            GIDP = sum(GIDP),
            .groups = "drop") %>%
  anti_join(pitchers) %>%
  filter(lgID %in% c('NL', 'AL')) %>%
  Lahman::battingStats(data = .) %>%
  group_by(playerID, stint) %>%
  mutate(year_num = row_number()) %>%
  ungroup() %>%
  group_by(playerID) %>%
  mutate(tenure = n()) %>%
  ungroup() %>%
  mutate(age = as.double((ymd(paste0(yearID, '-01-01')) - ymd(birthDate))/365)) %>%
  drop_na() %>%
  mutate(decade = yearID - (yearID %% 10)) %>%
  mutate(TBB = BB + IBB + HBP,         # combine all walk types
         TAB = AB + TBB + SH + SF) %>% # create total at-bats
  select(-c(BB, IBB, HBP, SH, SF))     # remove unneeded columns
```

Let me walk through the code above and explain what is happening and my thought process. 

First, we need to identify the pitchers in our Batting dataset and get rid of them. 
```
pitchers <- Lahman::Pitching %>%
  select(playerID) %>%
  distinct()
```

Next, I want to remove players from older eras. 
```
old_players <- People %>%
  filter(ymd(debut) < '1961-01-01')
```
Here is a good quote from [The Sport Journal on MLB Eras](https://thesportjournal.org/article/examining-perceptions-of-baseballs-eras/) explaining the ERAs:  

> A common list presented at Baseball-Reference described the eras as the Dead Ball Era (1901-1919), 
> the Live Ball Era (1920-1941), the Integration Era (1942-1960), the Expansion Era (1961-1976), 
> the Free Agency Era (1977-1993) and the Long Ball/Steroid Era (1994-2005) (17). This study runs 
> through the 2011 season and aseventh era will be added and labeled the Post Steroid Era (2006-2011).

I removed anyone who debuted before the Expansion Era (1961). Average tenure might change depending on the decade so this is something we should investigate in the EDA stage. 

I then removed anyone who doesn't have a final game and also if their final game is after 2018. I want players that are not currently playing and have finished their MLB career. This doesn't guarantee this but it comes close enough. 
```
filter(!is.na(finalGame)) %>%
  filter(ymd(finalGame) < '2018-01-01')
```

The next step is to make sure all players only have one entry per year. Some players have two (or more) for a year because they were traded or waived then picked up by another team. I don't really care about this so I am going to aggregate their stats to the year level.
```
group_by(playerID, yearID) %>%
  summarise(nameFirst = first(nameFirst),
            nameLast = first(nameLast),
            birthDate = first(birthDate),
            debut = first(debut),
            finalGame = first(finalGame),
            stint = first(stint),
            teamID = first(teamID),
            lgID = first(lgID),
            G = sum(G),
            AB = sum(AB),
            R = sum(R),
            H = sum(H),
            X2B = sum(X2B),
            X3B = sum(X3B),
            HR = sum(HR),
            RBI = sum(RBI),
            SB = sum(SB),
            CS = sum(CS),
            BB = sum(BB),
            SO = sum(SO),
            IBB = sum(IBB),
            HBP = sum(HBP),
            SH = sum(SH),
            SF = sum(SF),
            GIDP = sum(GIDP),
            .groups = "drop")
```

The next steps:  
1. Only include players from the NL and AL
```
filter(lgID %in% c('NL', 'AL'))
```
2. Use the function battingStats to calculate rate statistics like Batting Average, On-base Percentage, Slugging and OPS. 
```
Lahman::battingStats(data = .)
```
3. Calculate the year number in league for each player
```
group_by(playerID, stint) %>%
  mutate(year_num = row_number())
```
4. Calculate total tenure for each player
```
group_by(playerID) %>%
  mutate(tenure = n())
```
5. Calculate player age for each given year
```
mutate(age = as.double((ymd(paste0(yearID, '-01-01')) - ymd(birthDate))/365))
```
6. Calculate decade
```
mutate(decade = yearID %% 10)
```
7. Finally, calculate total walks and total plate appearances
```
mutate(TBB = BB + IBB + HBP,     # combine all walk types
       TAB = AB + TBB + SH + SF) # create total at-bats
```

All of this together gives us data for batters only that debuted after 1961. It gives us data for each year a batter was in the league. Let's take a look at my favorite player of all time and the greatest shortstop to play baseball to illustrate the structure (Ozzie Smith). Having each row be a year a player played in the league gives us the opportunity to teach a model how a person looks as a rookie that ultimately played in the league for 19 years. Ozzie debuted at age 23, got a ton of at-bats (668) and posted what is likely a below average OPS. 

```{r}
people_tenure %>%
  filter(playerID == 'smithoz01') %>%
  select(nameFirst, nameLast, yearID, year_num, age, TAB, OPS, tenure) %>%
  gt()
```


# EDA

Always look at the distributions of your variables.

```{r}
DataExplorer::plot_histogram(people_tenure)
```

Nothing jumps out to me. We definitely have some outliers, but we will check to see the effect after modeling.  

Next, let's check out how the variables interact with each other. A good way to investigate this is through a correlation matrix. If modeling with a linear model then you need to be concerned with how correlated the variables are with each other. 

The `corrplot` package has a great way to visualize this and on top of that will cluster your variables together using different cluster techniques. Here I chose a hierarchical clustering method with 5 clusters. 

```{r corrplot, message=FALSE}
library(corrplot)

cor_matrix <- people_tenure %>%
  select(-c(playerID, yearID, nameFirst, nameLast, birthDate, 
             debut, finalGame, stint, teamID, lgID)) %>%
  select(c(year_num, tenure, age, G, TAB, TBB, TB, SO, H, X2B, X3B, HR,
           BA, SlugPct, OBP, OPS, BABIP)) %>%
  cor()

corrplot(cor_matrix, order = "hclust", addrect = 5)
```

What's really cool about this is how we can see we have five different types of variables. Left corner we have the 'Time' stats: year_num & age. We then have the 'Rate' stats: BA, OBP, SlugPct, and OPS. Triples get grouped on their own because they happen so infrequently. Our target variable is by itself also, then we have the 'Counting' stats in the bottom right: Singles, Doubles, HRs, SOs, Walks, At Bats, & Games. Pretty neat to see them group like that. 

Let's see how the variables specifically correlate with our target variable Tenure. 

```{r tenure-corr, message=FALSE}
library(corrr)

people_tenure %>%
  select(-c(playerID, yearID, nameFirst, nameLast, birthDate, 
             debut, finalGame, stint, teamID, lgID)) %>%
  select(c(year_num, tenure, age, G, TAB, TBB, TB, SO, H, X2B, X3B, HR,
           SlugPct, OBP, OPS, BABIP)) %>%
  correlate() %>%
  stretch() %>%
  filter(x == "tenure") %>%
  arrange(desc(r)) %>%
  gt()
```

Interesting. We can use these correlations in helping us determine which variables to include in the models. 

Let's take a look at how decade relates to tenure to wrap up the EDA section. 

```{r decade-tenure, message=FALSE}
people_tenure %>%
  group_by(decade) %>%
  summarise(avg_tenure = mean(tenure)) %>%
  ggplot(aes(x = as_factor(decade), y = avg_tenure, fill = as_factor(decade))) +
  geom_col(stat = "identity") +
  theme(legend.position = "none")
```

There are slight differences in tenure at the tail ends. 

# Modeling

I have a rough outline when I model: 

1. Build simple linear baseline model
2. Build simple blackbox model
3. Analyze residuals from blackbox model
4. Feature engineer to try and correct large residuals
5. Tune hyper-paramenters for blackbox model

### Build A Simple Linear Baseline model

The reason to build a simple linear baseline model is to have an idea of how much a model has improved with the use of new models, hyper-parameter tuning, and future feature engineering. It also gives you an idea of how the variables interact with the target and the size of the effect.

I recommend making the first model by using the features you think are the most important. Include the bare minimum number of features. 

In this case of trying to predict MLB tenure, I think year_num, age, TAB (total at-bats), and OPS (on-base percentage + slugging percentage). I think year_num is going to be important because the longer you have been in the league then the longer your tenure will be. Age will be important because the younger you are then the longer you can be in the league. Total at-bats represent opportunity. If a player is getting opportunity then it either means the manager believes in the player or they are performing well. OPS represents performance. OPS is the sum of on-base percentage and slugging percentage. On-base is the rate of getting on base without consideration of how many bases the hit resulted in. Slugging percentage is the total bases on the hits divided by the at-bats. Slugging percentage is higher the more bases a batter gets. Home run hitters will have a higher slugging than single hitters. OPS is nice because it accounts for how often a batter gets on base and the total bases all in one metric. 

The fist model will be based on theory but I am also going to build a few other models using the variables that have the highest correlations to tenure.

Here's the formula for the theory model: `tenure ~ year_num + age + TAB + OPS`

Since we have isolated the target and the features we are most interested, we can visualize the relationship between all of the variables using a pair plot. There is a great package `GGally` that has a function `ggpairs` that products pair plots and is a great way to explore relationships and distributions.

```{r}
people_tenure %>%
  select(tenure, age, year_num, TAB, OPS) %>%
  ggpairs()
```

Let's fit the models and compare their performances.

```{r}
lm_theory <- lm(formula = tenure ~ year_num + age + TAB + OPS
          , data = people_tenure)

lm_corr1 <- lm(formula = tenure ~ year_num + TAB + OPS
          , data = people_tenure)

lm_corr2 <- lm(formula = tenure ~ year_num + TAB + OPS + TB + H + G
            , data = people_tenure)

lm_corr3 <- lm(formula = tenure ~ year_num + TAB + OPS + TB + H + G + TBB + X2B + HR + SO
            , data = people_tenure)
lm_corr4 <- lm(formula = tenure ~ year_num + age + TAB + OPS + TB + H + G + TBB + X2B + HR + SO + age + X3B + BABIP
            , data = people_tenure)

performance::compare_performance(lm_theory, lm_corr1, lm_corr2, lm_corr3, lm_corr4) %>%
  as_tibble() %>%
  select(Name, Model, R2, RMSE) %>%
  arrange(desc(R2)) %>%
  gt()
```

Nice, this is good to see. The theory model came in second and was only marginally behind the model that used every variable. An R^2 of .60 is also pretty good for only using 4 variables.

Let's look the coefficients to see which ones have the greatest impact on tenure.

```{r}
tidy(lm_theory) %>%
  mutate(estimate = round(estimate, digits = 3),
         std.error = round(std.error, digits = 3),
         statistic = round(statistic, digits = 3),
         p.value = round(p.value, digits = 3)) %>%
  gt()
```

All of the features are significant predictors of tenure with year_num being by far the most important. Every 1 year increase in year_num results in 1.22 more years of tenure. For every increase in age by 1 year, tenure is reduced by .7 years.  The theory of how long a player has been in the league, their age, their opportunity and their performance determining tenure seems to be a good theory. 

Let's check the model for the appropriate assumptions. 

```{r check-model, message = FALSE, fig.width = 8, fig.height = 10}
check_model(lm_theory, panel = TRUE)
```


#### Build a Simple Blackbox Model

Now is the time to build the simple blackbox model. In this case we are going to use the gradient boosted algorithm, xgBoost. I call it simple because the first go around we will be using the default hyper-parameters. There is a great package called `tidymodels` that will allow us to create workflows and the ability to quickly swap different machine learning algorithms. To learn more, here is a great resource: [Tidy Models bookdown TMRW](https://www.tmwr.org/)

First, split the data into train and test datasets.

```{r}
set.seed(123)
pt_split <- initial_split(people_tenure, prop = 3/4)
pt_train <- training(pt_split)
pt_test <- testing(pt_split)
```

We define the two formulas that we are going to be using and fit the models. We then collect the metrics and put them together for easy comparison. 

```{r}

theory_formula <- formula(tenure ~ year_num + age + TAB + OPS)
all_metrics_formula <- formula(tenure ~ year_num + age + TAB + OPS + TB + H + G + TBB + X2B + HR + SO + age + X3B + BABIP)

lm_theory <- linear_reg() %>%
  fit(theory_formula, data = pt_train)

lm_all <- linear_reg() %>%
  fit(theory_formula, data = pt_train)

xgb_theory <- boost_tree(mode = "regression") %>%
  set_engine("xgboost") %>%
  fit(theory_formula, data = pt_train)

xgb_all <- boost_tree(mode = "regression") %>%
  set_engine("xgboost") %>%
  fit(all_metrics_formula, data = pt_train)

lm_theory_metrics <- lm_theory %>%
  predict(pt_test) %>%
  bind_cols(pt_test) %>%
  metrics(truth = tenure, estimate = .pred) %>%
  mutate(model = "lm_theory") %>%
  select(model, .metric, .estimate) %>%
  pivot_wider(names_from = .metric, values_from = .estimate)

lm_all_metrics <- lm_all %>%
  predict(pt_test) %>%
  bind_cols(pt_test) %>%
  metrics(truth = tenure, estimate = .pred) %>%
  mutate(model = "lm_all") %>%
  select(model, .metric, .estimate) %>%
  pivot_wider(names_from = .metric, values_from = .estimate)

xgb_theory_metrics <- xgb_theory %>%
  predict(pt_test) %>%
  bind_cols(pt_test) %>%
  metrics(truth = tenure, estimate = .pred) %>%
  mutate(model = "xgb_theory") %>%
  select(model, .metric, .estimate) %>%
  pivot_wider(names_from = .metric, values_from = .estimate)

xgb_all_metrics <- xgb_all %>%
  predict(pt_test) %>%
  bind_cols(pt_test) %>%
  metrics(truth = tenure, estimate = .pred) %>%
  mutate(model = "xgb_all") %>%
  select(model, .metric, .estimate) %>%
  pivot_wider(names_from = .metric, values_from = .estimate)

lm_theory_metrics %>%
  bind_rows(lm_all_metrics, xgb_theory_metrics, xgb_all_metrics) %>%
  arrange(rmse) %>%
  gt()

```


The xgBoost model using the theory formula and default hyper-parameters outperformed the linear model by not much. We know the most important variables in the linear model was year_num, age, TAB, and OPS in the order. Let's see what variables were the most important to the xgBoost theory model. 


```{r, message=FALSE}
library(vip)

xgb_theory %>%
  vip(geom = "col")
```


Age becomes less important in the xgBoost model and total at-bats becomes more important. 

# Examine xgBoost Predictions

We know how the model performed on the test data. On average the xgBoost model was off +/- 2.44 years. Let's see how it predicted Ozzie Smith. 

```{r}
xgb_theory %>% 
  predict(people_tenure) %>%
  bind_cols(people_tenure) %>%
  filter(playerID == 'smithoz01') %>%
  select(nameFirst, nameLast, yearID, year_num, age, TAB, OPS, tenure, .pred) %>%
  gt()
```


You can see the model is off by quite a bit for Ozzie Smith. The model predicts around 11 years until year number 8. From the average tenure by decade plot, we know the average tenure is around 9.5 years so the model was defaulting close to the average. I picked Ozzie not only because he is my favorite player, but because his value was derived from his defense and this model currently does not account for defensive production. Ozzie Smith won 13 gold gloves meaning he was the best at his position for 13 of the 19 years in the MLB. We would expect the model to be off for this type of player. In the future, we will obviously need to account for this. 

Let's take a look at a great offensive player and see if the model does better. Unfortunately the greatest offensive player, Hank Aaron, isn't in our dataset because he debuted before 1961, but the next best hitter in our dataset might be Tony Gwynn so let's take a look at him.

```{r}
xgb_theory %>% 
  predict(people_tenure) %>%
  bind_cols(people_tenure) %>%
  filter(playerID == 'gwynnto01') %>%
  select(nameFirst, nameLast, yearID, year_num, age, TAB, OPS, tenure, .pred) %>%
  gt()
```

It's good to see the model start off higher for Gwynn's rookie year and even predicts 15 years of tenure for him in year number 3. The model then gets closer and closer to the right answer as the years pass. 

Now, let's do the fun part and see how it predicts some MLB players early in their career. The three I am going to be looking at are young phenoms; Ronald Acuna, Fernando Tatis, & Juan Soto. 

```{r}
young_phenoms <- People %>%
  select(playerID, nameFirst, nameLast, birthDate, debut, finalGame) %>%
  filter(playerID %in% c('acunaro01', 'tatisfe02', 'sotoju01')) %>%
  inner_join(Batting) %>%
  group_by(playerID, yearID) %>%
  summarise(nameFirst = first(nameFirst),
            nameLast = first(nameLast),
            birthDate = first(birthDate),
            debut = first(debut),
            finalGame = first(finalGame),
            stint = first(stint),
            teamID = first(teamID),
            lgID = first(lgID),
            G = sum(G),
            AB = sum(AB),
            R = sum(R),
            H = sum(H),
            X2B = sum(X2B),
            X3B = sum(X3B),
            HR = sum(HR),
            RBI = sum(RBI),
            SB = sum(SB),
            CS = sum(CS),
            BB = sum(BB),
            SO = sum(SO),
            IBB = sum(IBB),
            HBP = sum(HBP),
            SH = sum(SH),
            SF = sum(SF),
            GIDP = sum(GIDP),
            .groups = "drop") %>%
  Lahman::battingStats(data = .) %>%
  group_by(playerID, stint) %>%
  mutate(year_num = row_number()) %>%
  ungroup() %>%
  filter(yearID == 2019) %>%
  group_by(playerID) %>%
  mutate(tenure = n()) %>%
  ungroup() %>%
  mutate(age = as.double((ymd(paste0(yearID, '-01-01')) - ymd(birthDate))/365)) %>%
  drop_na() %>%
  mutate(decade = yearID %% 10) %>%
  mutate(TBB = BB + IBB + HBP,         # combine all walk types
         TAB = AB + TBB + SH + SF) %>% # create total at-bats
  select(-c(BB, IBB, HBP, SH, SF))     # remove unneeded columns

xgb_theory %>% 
  predict(young_phenoms) %>%
  bind_cols(young_phenoms) %>%
  select(nameFirst, nameLast, yearID, year_num, age, TAB, OPS, tenure, .pred) %>%
  gt()
```

Based on 2019 data, the model expects Ronald Acuna to be in the league the longest but they all are very close to each other. Again, this is good to see. Most experts would predict these young players to be in the league for a very long time and 16 years is definitely a long time. 

Now let's look at rookies from 2018, 2019 and 2020 and predict their tenure using 2020 data. 2020 was a short season due to the COVID-19 pandemic so we will have to extrapolate total at-bats from the 60 game season to a regular 162 game season. 

```{r}
rooks <- People %>%
  select(playerID, nameFirst, nameLast, birthDate, debut, finalGame) %>%
  filter( year(ymd(debut)) %in% c(2018, 2019, 2020)) %>%
  inner_join(Batting) %>%
  group_by(playerID, yearID) %>%
  summarise(nameFirst = first(nameFirst),
            nameLast = first(nameLast),
            birthDate = first(birthDate),
            debut = first(debut),
            finalGame = first(finalGame),
            stint = first(stint),
            teamID = first(teamID),
            lgID = first(lgID),
            G = sum(G),
            AB = sum(AB),
            R = sum(R),
            H = sum(H),
            X2B = sum(X2B),
            X3B = sum(X3B),
            HR = sum(HR),
            RBI = sum(RBI),
            SB = sum(SB),
            CS = sum(CS),
            BB = sum(BB),
            SO = sum(SO),
            IBB = sum(IBB),
            HBP = sum(HBP),
            SH = sum(SH),
            SF = sum(SF),
            GIDP = sum(GIDP),
            .groups = "drop") %>%
  Lahman::battingStats(data = .) %>%
  group_by(playerID, stint) %>%
  mutate(year_num = row_number()) %>%
  ungroup() %>%
  group_by(playerID) %>%
  filter(yearID == max(yearID)) %>%
  ungroup() %>%
  mutate(age = as.double((ymd(paste0(yearID, '-01-01')) - ymd(birthDate))/365)) %>%
  drop_na() %>%
  mutate(decade = yearID %% 10) %>%
  mutate(TBB = BB + IBB + HBP,         # combine all walk types
         TAB = AB + TBB + SH + SF) %>% # create total at-bats
  select(-c(BB, IBB, HBP, SH, SF)) %>% # remove unneeded columns
  mutate(TAB = (TAB/60)*162)

xgb_theory %>% 
  predict(rooks) %>%
  bind_cols(rooks) %>%
  select(nameFirst, nameLast, year_num, age, TAB, OPS, .pred) %>%
  arrange(desc(.pred)) %>%
  head(10) %>%
  gt()
```

This great to see and passes the eye-test extremely well. All of those young players are some of the best in the league and we would expect them to be on the top of the list if we were to predict tenure. 

# Next Steps
Now that we have a base model, we can start to improve it. The next steps are:

1. Analyze the times our model was the most wrong and see if there is a pattern
2. Based on step one, we then introduce new features to correct large errors
3. Finally, we need to tune the hyper-parameters for our model. 

All those steps will be covered in the next blog post. 
